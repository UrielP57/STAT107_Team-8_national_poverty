---
title: 'Do different Variables influence the Poverty Rate of the World?'
author: "Uriel S. Pacheco-Guerrero, Donnie, Marianne"
date: '2025-10-14'
output:
  pdf_document: default
  html_document: default
---
### Introduction
# Purpose:
The purpose of this experiment is to figure out if the choose independent variables not only prove that to influence the Poverty Headcount ratio. But to potentially figure out if by building a linear regression (either with transformation or alternative one) can help fores the next decades world wide poverty rate. The result of this research can help organization as United Nations to create a movement to either compile member nations to invest more of their GDP into education and improving their individual economies. And whatever policies they move will affect businesses on all levels and those on a consumer level. 

# Question
-Main Question: Is the choose variables of average of; Education% per GDP, Unemployment, Population growth, Inflation able to influence the Poverty rate of the world?

-Sub-Question: Is it possible to forecast the Poverty headcount ratio for the foreseeable future. 
 
# Benefit:
This analysis should be to benefit government institutions that not only track but try to influence how much inflation would inflict upon society as a whole. Additionally knowing whether not a country like United Kingdom can reduce their nation's Poverty rate if unemployment is deemed the most influencing variable. The same applies for population growth however that is less controllable while being confined to moral reasons. 

# Plan:
We hope to answer our question since, if it is determined that the independent variables have a significant ability to influence the Poverty head count ratio. Then going forward it would be possible to train a model that could potential forecast which would help government bodies worldwide create plans to counteract these shifts.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data 
There are currently five different data sets, all of which are from World Bank Group database. The dependent variable is currently referencing to Poverty Headcount ratio or Poverty rate for short($3.00 a day) being names as ND. The independent variables are about annual Population growth by percent (Pop_Growth), Inflation consumer price (API), Education Statistic (KSI), Unemployment rate based of countries total (KSI, because I was going insane). There was additional information provided with Poverty rate, inflation and Population growth however it was not important enough to add. 
## Data sets:
```{r}
library(stargazer)
library(car)
require(graphics)
library(tidyverse)
ND <- read.csv("New_DDAY.csv", skip = 4)
hot <- ND[-2:-4]
API <- read.csv("API_A.csv", skip = 4)
hot_2 <- API[-2:-4]
Pop_Growth <- read.csv("Pop_Growth.csv", skip = 4)
hot_3 <- Pop_Growth[-2:-4]
unemployment <- read.csv("Unemployment.csv", skip = 4)
hot_4 <- unemployment[-2:-4]
Education <- read.csv("Education.csv", skip =4)
hot_5 <- Education[-2:-4]
```

## Cleaning the Data:
For all the data sets being presented here, all were downloaded in a wide form for an excel spread sheet. Any other method did not work, which is why for the idea to work I needed to have it in long form. So after stripping each row, I would divide each row into groups of 270 of 65 indexes long. Then i would be able to create a new data frame for each csv file so it be easier to ru further code and not look like an eyesore otherwise. The associated varible names were df_ND,df_API,df_PG,df_Unemp,df_ed.

# Code for ND

```{r}
df_pr <- pivot_longer(hot, cols = X1960:X2024, names_to = "Years", names_prefix = "X", values_to = "Poverty Rate")
df_INf <- pivot_longer(hot_2, cols = X1960:X2024, names_to = "Years", names_prefix = "X", values_to = "Inflation")
df_PG <- pivot_longer(hot_3, cols = X1960:X2024, names_to = "Years", names_prefix = "X", values_to = "Population Growth")
df_Unempo <- pivot_longer(hot_4, cols = X1960:X2024, names_to = "Years", names_prefix = "X", values_to = "Unempolyment")
df_ED <- pivot_longer(hot_5, cols = X1960:X2024, names_to = "Years", names_prefix = "X", values_to = "Edcuation")
```


```{r}
df_lm <- merge(df_pr,df_INf)
df_lm <-merge(df_lm, df_PG)
df_lm <- merge(df_lm, df_Unempo)
df_lm <- merge(df_lm, df_ED)
View(df_lm)

```


```{r}
swappy_swappy <- function(df){
  row <- c() 
  mid <- c()
  not_imp <- c() #useless vector
  for (ind_row in rownames(df)){
    for (i in df[ind_row,]){
      RC <- as.character(i)
      if (is.na(RC)){
        RC <- 0
        row <- c(row, RC)
        
       } else {
         vari_RC <- suppressWarnings(as.numeric(RC))
                                        
                                        
          if (!is.na(vari_RC)){
            row <- c(row, RC)
            }  else if (RC != ""){
            not_imp <- c(not_imp, RC)
            }
      }
    }
  }
  df_by_65 <- rep(1:270, each = 65)
  fin <- split(row, df_by_65)
  return(fin)
}

```

# Data frame cleaning for Poverty Rate:
```{r}
fin_ND <- swappy_swappy(ND)
col_nm_all <- ND[,1][5:270]
df_ND <- data.frame(fin_ND[5:270])
colnames(df_ND) <- c(col_nm_all)
years <- c(1960:2024) 
rownames(df_ND) <- c(years)

df_ND$idea <- ifelse(df_ND$Aruba >= 0, 0)
for (idk in colnames(df_ND)){
  df_ND$idea <- as.numeric(df_ND$idea) + as.numeric(df_ND[[idk]])
  df_ND$Poverty_rate <- ifelse(df_ND$Aruba >= 0, df_ND$idea/ 270)
}
```

# Data Frame cleaning for Inflation:
```{r}
fin_API <- swappy_swappy(API)

col_nm_2 <- API[,1][5:270]
df_API <- data.frame(col_nm = fin_API[5:270])

colnames(df_API) <- c(col_nm_2)
rownames(df_API) <- c(years)
df_API$idea <- ifelse(df_API$Aruba >= -1, 0,0)
for (idk_2 in colnames(df_API)){
  df_API$idea <- as.numeric(df_API$idea) + as.numeric(df_API[[idk_2]])
  df_ND$`Inflation` <- ifelse(df_API$Aruba >= -1, df_API$idea/ 270, 0)
}
```

#Data Farme Cleaning for Population growth:
```{r}
fin_PG <- swappy_swappy(Pop_Growth)

col_nm_3 <- Pop_Growth[,1][5:270]
df_PG <- data.frame(col_nm = fin_PG[5:270])

colnames(df_PG) <- c(col_nm_3)
rownames(df_PG) <- c(years)
df_PG$idea <- ifelse(df_PG$Aruba >= -1, 0,0)
for (idk_3 in colnames(df_API)){
  df_PG$idea <- as.numeric(df_PG$idea) + as.numeric(df_PG[[idk_3]])
  df_ND$`Population` <- ifelse(df_PG$Aruba >= -10000,0, df_PG$idea/ 270)
}
```

#Data Frame Cleaning for Unemployment
```{r}
fin_unempo <- swappy_swappy(unemployment)

col_nm_4 <- unemployment[,1][5:270]
df_unemployment <- data.frame(fin_unempo[5:270])

colnames(df_unemployment) <- c(col_nm_4)
rownames(df_unemployment) <- c(years)

df_unemployment$idea <- ifelse(df_unemployment$Aruba >= -1, 0,0)
for (idk_4 in colnames(df_unemployment)){
  df_unemployment$idea <- as.numeric(df_unemployment$idea) + as.numeric(df_unemployment[[idk_4]])
  df_ND$`Unemployment` <- ifelse(df_unemployment$Aruba >= -10000,df_unemployment$idea/ 270,0)
}
```

#Data Frame Cleaning for Education % from GDP
```{r}
fin_ed <- swappy_swappy(Education)

col_nm_ed <- Education[,1][5:270]
df_ed <- data.frame(col_nm_ed = fin_ed[5:270])

colnames(df_ed) <- c(col_nm_ed)
rownames(df_ed) <- c(years)
df_ed$Education <- ifelse(df_ed$Aruba >= -1, 0,0)
for (idk_ed in colnames(df_ed)){
  df_ed$Education <- as.numeric(df_ed$Education) + as.numeric(df_ed[[idk_ed]])
  df_ND$`Education % from GDP` <- ifelse(df_ed$Aruba >= -10000,df_ed$Education/ 270)
}
df_ND$Time <- ifelse(df_ed$Aruba >= -10000, c(1960:2024))
```


#Visuals
```{r}
example <- df_ND[-38,]
ex_2 <- example[-61,]
df_ND_w_n_out <- ex_2[-42,]
#I bascially removed year data for everything for 2002, 1997, 2021
#eveythign below, we will be comapring three lm(), one w. tranformation, and the oher two both have poly() but the third one has the secon'd one's outliers removed.


by_colors <- ifelse(df_ND$Poverty_rate != df_ND$Poverty_rate, rainbow(6), rainbow(6))
pairs(df_ND[268:273], main = "Variable Relationship w/ outliers", pch = 21, bg = by_colors, lower.panel = NULL)
pairs(df_ND_w_n_out[268:273], main = "Variable Relationship w/ no outliers", pch = 21, bg = by_colors, lower.panel = NULL)
cor(df_ND$`Poverty_rate`,df_ND$Inflation)
cor(df_ND$`Poverty_rate`,df_ND$Population)
#Population is the weakest, but its the only one that has a negative classification
cor(df_ND$`Poverty_rate`,df_ND$Unemployment)
cor(df_ND$`Poverty_rate`,df_ND$`Education % from GDP`)
cor(df_ND$`Poverty_rate`,df_ND$Time)
print("gap")
cor(df_ND_w_n_out$`Poverty_rate`,df_ND_w_n_out$Inflation)
cor(df_ND_w_n_out$`Poverty_rate`,df_ND_w_n_out$Population)
#Population is the weakest, but its the only one that has a negative classification
cor(df_ND_w_n_out$`Poverty_rate`,df_ND_w_n_out$Unemployment)
cor(df_ND_w_n_out$`Poverty_rate`,df_ND_w_n_out$`Education % from GDP`)
cor(df_ND_w_n_out$`Poverty_rate`,df_ND_w_n_out$Time)
```


Dependent Variable is Poverty rate of the World:
For every 1 increase in percentage for Inflation, it is expected that the Poverty rate will increase by 0.07% points at years end.

For every additional rise in percentage for Population growth,it is expected that the Poverty rate will decrease by -0.09% points at years end.

For every rise in percentage for Unemployment, it is expected that the Poverty rate will increase by .48% points.

For every rise in Education in percent, it is expected that the Poverty rate will decrease by -.10% points.

The only independent variables that would of have passed the p-level of 0.05 is Inflation and Unemployment. However only Unemployment passes a p-level of 0.01.

## Visualization:
VIF = measures if multicolineairty: to see if the variables are truly independent of each other. 
Honestly, the result for the variables are quite high however they are still lower than 5. So they are somewhat influecning each other, though not to the level that it would bring sway to the results. 

IMPORTANT: if I add time as a variable, causes r^2 to rise slightly but when if comes to looking for truely independence. Time influnces Unemployment and Education, since it being 7.326.


Analysis:
If we run a null test at a p-level of .05, this would of been our results. 

After running the glm function, only two of the five independent variables ended up being able to pass a p-level of 0.05 and below. They were Unemployment and Time; where unemployment is sitting conformable at 4.780527e-03 and Time's main variable is at 5.352967e-04. However I would want to clarify that Time was transformed using poly(x, n). which allowed it to gain ***. However for Unemployment it still would've passed but it would of been a much lower number.
Outlines: There were three notable points that  kept on appearing when ploting the glm():2002, 1997 and 2021. These outlines are quite fantasizing since 2021 is during the year of which Covid-19 was the most rampant. While in 2002, the war on terror speech from president bush occurred (????idk). Lastly in 1997, there was a market crises in many Asian countries, where unemployment, wage declines and many currencies fell against the US dollar.

```{r}



life <- lm(Poverty_rate ~ Inflation + Population + Unemployment + `Education % from GDP` + Time, data = df_ND)
life_outliers <-lm(Poverty_rate ~ Inflation + Population + Unemployment + `Education % from GDP` + poly(Time, 3), data = df_ND_w_n_out)
life_m7 <- lm(Poverty_rate ~ Inflation + Population + Unemployment + `Education % from GDP` + poly(Time, 3), data = df_ND)
stargazer(life, life_m7, life_outliers,
          title="Poverty rate lm",
          header=F,
          font.size = "tiny",
          type = "text",
          algin = T,
          single = F,
          column.sep.width = "1pt",
          digits =2)
```

```{r}
library(car)
require(graphics)
plot(life_m7)
plot(life)
plot(life_outliers)
```

```{r}
barplot(vif(life))
barplot(vif(life_m7))
barplot(vif(life_outliers))
vif(life)
vif(life_outliers)
vif(life_m7)
```
